Self users manual
*****************

***
The most reliable and up to date information about available commands is available by reading the code in self_dot.py and IO.py
However, summaries of some commands are given below.
Some commands listed below may be deprecated
***

python communication.py save <valgfritt navn - hvis ikke noe navn, blir navnet brain, hvor de enkelt nettverkene heter brainUUID>
python communication.py load <brain_name, altså prefiks uten UUID>

python communication.py selfvoice mode
mode can be ['partikkel', 'spectral', 'noiseband']

python communication.py autolearn status
python communication.py autorespond status
- status can be 1 or 0, True or False
These modes use automatic segmentation to trigger learning or responding after a segemnt of audio has been input

python learnrespond.py <time> association

python communication.py inputLevel mode
- mode can be mute, unmute or reset
The reset mode mutes for 1 second, then unmutes

python communication.py csinstr [string]
Send generic Csound instrument event
Can be used to set any chn value, via instrument 22 ('i 22 0 1 \"name\" value')
On Linux the quotes should not be escaped (don't use \ before " in the string)

python communication.py calibrateAudio
Sense signal level (keep relatively quiet for maximum range), set a soft knee noise gate. Also analyze background noise print.
For comparision the gate can be disabled with 
communication.py csinstr i -17 0 1
and re-enabled with 
communication.py csinstr i 17 0 -1
Each time calibrateAudio is run, it will set a new noise floor level and enable the gate. 
The noise print is used in instr 14, removing the spectral profile of the bacground noise from the input before any other processing.
Instr 14 also has a method for suppressing self's own audio input (reduce feedback and general clutter), the level of selv suppression can be set with an argument (p4) to instr 14.
The noise reduction and sel suppression of instr 14 is enabled automatically when running calibrateAudio. 
For comparision the noise reduction can be disabled with 
communication.py csinstr i -14 0 1
and re-enabled with 
communication.py csinstr i 14 0 -1

Input monitoring
For diagnostic use, one could monitor the input signal directly. This can be enabled by setting the desired volume in the "inputMonitor" chn channel.
This can be done with 
communication.py csinstr i 22 0 1 \"inputMonitor\" 0.2
The last value (here 0.2) represent the desired monitor level.

Self suppression
When calibrateAudio has been run, we filter out the background noise and also selectively remove self's own output frequencies from the input. 
Still, under certain conditions (using laptop speaker and microphone) it may be necessary to "duck" the input when self is speaking, 
to avoid self to respond to own statements. Self ducking can be enabled with
python communication.py selfDucking 1

Pan position analysis of audio input
The stereo position if input sound is analyzed. It requires a stereo microphone setup of 2 omni microphones with a Jecklin disk or other kind of acoustical separation. Distance between the microphones is assumed to be 20 cm. Pan position output is written to two chn channels: "inputPosition_idt" and "inputPosition_rms", each representing the output of two different methods of analysis (Inter aural time delay, and RMS level difference).

Exit from Csound
We are using Python from within Csound, this may cause problems with termination via Ctrl+C on some platforms since the Python interpreter in Csound does not receiv e the exit signal. To alleviate this, we use an instrument containing the exitnow opcode, terminating Csound when the instrument is called. This resides in instrument 9999. This can be called from communication.py like this:
communication.py csinstr i 9999 0 1

Map audio analysis directly to synthesis
This can be done with the mapping instruments 44 and 45. Instr 45 contains macros to map a set of parameters, while instr 44 provides mapping of single parameters ffor a more explorative approach. 
Instr 45 is called with a keyword to select the macro appplied, e.g.:
python communication.py csinstr i 45 0 1 1 \"partikkel\"
The available macros can be found in the cound code for instr 45 (may be updated and changed frequently)
To turn off a macro mapping, use the corresponding command with negative p4, eg.:
python communication.py csinstr i 45 0 1 - \"partikkel\"
Instr 44 can be called like this: 
python communication.py csinstr i 44.1 0 -1 \"centroid1\" \"partikkel1_wavfreq\" 1 0
Where p3 sets the duration that the mapping will be active (infinitely in the example above).
Do note that a fractional instr number (e.g. 44.1) is needed to allow several mappings to coexist simultaneously. 
This also allows separate mappings to be turned on and off individually.
* Note: When experimenting with direct mapping of input analysis parameters like this, it is practical (needed) to turn off the resetting of channel values done on empty brain states in IO.py. This automatic zeroing can be enabled or disabled by using 
python communication.py zerochannels 0
(0 = disable, 1 = enable)

Test signals for learning
A selection of test sounds for speech (radio programs) can be found at http://oeyvind.teks.no/ftp/speech_samples/
To enable playback of these, modify "testscore.inc" to reflect the path to the sound files on your system, and uncomment the line 
;#include "testscore.inc" 
in the file "self_dot.csd
(semicolon is comment in Csound)

Recording of learned audio input
Recording should be active at all times under normal running conditions. Still it is not enabled by default during the development process.
To enable recording:
python communication.py memoryRecording 1
and to disable:
python communication.py memoryRecording0

** Learnrespond contains timed macros for certain communication events
python learnrespond.py [time, mode, file]
optional arguments [time, mode, filename] are:
- time: set period in seconds for learning or responding, default 5
- mode: learn, respond, both, (should be self explanatory), ... filelearn, filerespond (use sound file as input)
- filename: name of sound file for input to learn or respond

Learning associations:
python communication.py associate 1/0
This makes self associate sound1 -> sound2, i.e. it will listen for two sounds, and will respond with latter based on the former. 


